{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2545,
     "status": "ok",
     "timestamp": 1699872372800,
     "user": {
      "displayName": "Hasan Amin",
      "userId": "17461130678708299500"
     },
     "user_tz": 300
    },
    "id": "SFClpvPNcvH4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 00:13:54.737263: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-19 00:13:54.737331: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-19 00:13:54.737351: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-19 00:13:54.777129: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17898,
     "status": "ok",
     "timestamp": 1699872394960,
     "user": {
      "displayName": "Hasan Amin",
      "userId": "17461130678708299500"
     },
     "user_tz": 300
    },
    "id": "rYTna-WMgWXE",
    "outputId": "4ec824f2-9409-4fe2-a979-b65f63cd6f54"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "WIDTH = 28\n",
    "NUM_CHANNELS = 1\n",
    "NUM_TRAIN = 60000\n",
    "NUM_TEST = 10000\n",
    "NUM_DEV = 100\n",
    "\n",
    "DATASET = \"mnist\"\n",
    "BASE_DIR = \"\"\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqNEYLvZKW2T"
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699872397890,
     "user": {
      "displayName": "Hasan Amin",
      "userId": "17461130678708299500"
     },
     "user_tz": 300
    },
    "id": "dmyOUizW9Kde"
   },
   "outputs": [],
   "source": [
    "def _normalize(X):\n",
    "  assert X.dtype == np.uint8\n",
    "  X = X.astype(np.float64)\n",
    "  X /= 255\n",
    "  return X\n",
    "\n",
    "def load_standard_mnist():\n",
    "  (X_train, Y_train), (X_validation, Y_validation) = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "  X_train = X_train.reshape(X_train.shape[0], WIDTH, WIDTH, 1)\n",
    "  X_validation = X_validation.reshape(X_validation.shape[0], WIDTH, WIDTH, 1)\n",
    "\n",
    "  X_train = _normalize(X_train)\n",
    "  X_validation = _normalize(X_validation)\n",
    "\n",
    "  Y_train = Y_train.astype(np.int32)\n",
    "  Y_validation = Y_validation.astype(np.int32)\n",
    "\n",
    "  return X_train, Y_train, X_validation, Y_validation\n",
    "\n",
    "def load_mnist_train_dev():\n",
    "  # these were randomly picked, then fixed for future\n",
    "  selected_dev = [8106, 9910, 3397, 8870, 2103, 5689, 9799, 4037, 1584, 1160, 9063,\n",
    "       1332, 3043, 8307, 1042, 3466, 7772, 7327, 7098, 7216, 8624, 6400,\n",
    "       5811, 1862, 7327, 1626, 5958, 3868, 3795,  836, 3406, 5570, 9535,\n",
    "       9653, 7890, 5671, 2451, 9175, 8310, 2425, 5923, 2797, 1150, 6012,\n",
    "       8666, 8849, 6839, 5994, 6751, 9139, 9648, 8898, 9869, 2184, 1363,\n",
    "       8294, 4000, 5424, 4544,  330, 4325, 4597, 4735, 9966, 2342, 7220,\n",
    "       5774, 3437, 4276,  760, 7868, 2993, 6262, 8880, 6017, 5045, 9513,\n",
    "       4084, 7115, 5775,  358, 3549, 2612, 8973, 6747,  415, 8573, 9973,\n",
    "       2734,  586, 3937, 6889, 1191, 5255, 1460,  413, 7257, 5272, 7402,\n",
    "       7968]\n",
    "  X_train, Y_train, X_validation, Y_validation = load_standard_mnist()\n",
    "  X_dev = X_validation[selected_dev]\n",
    "  Y_dev = Y_validation[selected_dev]\n",
    "  return X_train, Y_train, X_dev, Y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2126,
     "status": "ok",
     "timestamp": 1699872400013,
     "user": {
      "displayName": "Hasan Amin",
      "userId": "17461130678708299500"
     },
     "user_tz": 300
    },
    "id": "72CIR269ttN7",
    "outputId": "4a323639-6fc1-45dc-df3a-cfcec594fefa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_standard_mnist()\n",
    "_, _, X_dev, Y_dev = load_mnist_train_dev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1699872400014,
     "user": {
      "displayName": "Hasan Amin",
      "userId": "17461130678708299500"
     },
     "user_tz": 300
    },
    "id": "DhlLQi-CtwYV"
   },
   "outputs": [],
   "source": [
    "Y_train = np.squeeze(np.array(Y_train))\n",
    "Y_test = np.squeeze(np.array(Y_test))\n",
    "Y_dev = np.squeeze(np.array(Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1699872400014,
     "user": {
      "displayName": "Hasan Amin",
      "userId": "17461130678708299500"
     },
     "user_tz": 300
    },
    "id": "2nWT1geeEIiY",
    "outputId": "08af344b-3db3-42b2-9158-bdaabbb73bee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1) (100, 28, 28, 1) (60000,) (10000,) (100,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, X_dev.shape, Y_train.shape, Y_test.shape, Y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxbL-tx2iRAI"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1699872561923,
     "user": {
      "displayName": "Hasan Amin",
      "userId": "17461130678708299500"
     },
     "user_tz": 300
    },
    "id": "f_6UNAZZiSOb"
   },
   "outputs": [],
   "source": [
    "def deep_model():\n",
    "  model = tf.keras.Sequential((\n",
    "      tf.keras.layers.Flatten(input_shape=(WIDTH, WIDTH), name='input', dtype=np.float64),\n",
    "      tf.keras.layers.Dense(256, name='hidden1', activation='relu', dtype=np.double),\n",
    "      tf.keras.layers.Dense(128, name='hidden2', activation='relu', dtype=np.double),\n",
    "      tf.keras.layers.Dense(64, name='hidden3', activation='relu', dtype=np.double),\n",
    "      tf.keras.layers.Dense(32, name='hidden4', activation='relu', dtype=np.double),\n",
    "      tf.keras.layers.Dense(NUM_CLASSES, name='logits', dtype=np.float64),\n",
    "      tf.keras.layers.Activation(tf.nn.softmax, name='softmax', dtype=np.float64)))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "saved_epochs = [100, 1000, 5000, 10000]\n",
    "\n",
    "start_epoch = 0\n",
    "for e in saved_epochs:\n",
    "    try:\n",
    "        clf = tf.keras.models.load_model(f\"{BASE_DIR}/{DATASET}_{e}e_{pct_poison}dp.h5\")\n",
    "        start_epoch = e\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "if start_epoch == 0:\n",
    "    clf = deep_model()\n",
    "    clf.compile(\n",
    "        optimizer='Adam', \n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "        metrics=['accuracy', tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5)]\n",
    "    )\n",
    "\n",
    "print(start_epoch)\n",
    "for i in range(start_epoch+1,EPOCHS+1):\n",
    "  if (i%10) == 0:\n",
    "    print(i)\n",
    "  clf.fit(X_train, Y_train, epochs=1, batch_size=BATCH_SIZE, validation_data=(X_test, Y_test), verbose=2)\n",
    "  if i in saved_epochs:\n",
    "    clf.save(f\"{BASE_DIR}/{DATASET}_{i}e.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1y02mt7wreMTrj_of2FlO4_T83Kv_MT7f",
     "timestamp": 1582082487815
    },
    {
     "file_id": "14DIzFCY9dCZ50AUOTaZlEHNMsPOkmMFo",
     "timestamp": 1581982962256
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mdl",
   "language": "python",
   "name": "mdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
