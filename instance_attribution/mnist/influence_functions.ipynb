{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3131,
     "status": "ok",
     "timestamp": 1662712278297,
     "user": {
      "displayName": "Hasan Amin",
      "userId": "17461130678708299500"
     },
     "user_tz": 240
    },
    "id": "KqbFELV9m40B"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4628,
     "status": "ok",
     "timestamp": 1662712282916,
     "user": {
      "displayName": "Hasan Amin",
      "userId": "17461130678708299500"
     },
     "user_tz": 240
    },
    "id": "bwASQ3ySmWrL",
    "outputId": "bbe600c2-1fc5-4b17-bb76-89f46453d474"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.disable_v2_behavior()\n",
    "\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCaiV_qeqge8"
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1662712301348,
     "user": {
      "displayName": "Hasan Amin",
      "userId": "17461130678708299500"
     },
     "user_tz": 240
    },
    "id": "QFO36YCHTYh9"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"\"\n",
    "NUM_CLASSES=10\n",
    "WIDTH = 28\n",
    "NUM_CHANNELS = 1\n",
    "\n",
    "def _normalize(X):\n",
    "  assert X.dtype == np.uint8\n",
    "  X = X.astype(np.float64)\n",
    "  X /= 255\n",
    "  return X\n",
    "\n",
    "def get_one_hot(targets, nb_classes):\n",
    "  res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "  return res.reshape(list(targets.shape)+[nb_classes])\n",
    "  \n",
    "def load_standard_mnist():\n",
    "  (X_train, Y_train), (X_validation, Y_validation) = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "  X_train = X_train.reshape(X_train.shape[0], WIDTH, WIDTH, 1)\n",
    "  X_validation = X_validation.reshape(X_validation.shape[0], WIDTH, WIDTH, 1)\n",
    "\n",
    "  X_train = _normalize(X_train)\n",
    "  X_validation = _normalize(X_validation)\n",
    "\n",
    "  Y_train = Y_train.astype(np.int32)\n",
    "  Y_validation = Y_validation.astype(np.int32)\n",
    "\n",
    "  return X_train, Y_train, X_validation, Y_validation\n",
    "\n",
    "def load_mnist_train_dev():\n",
    "  # these were randomly picked, then fixed for future\n",
    "  selected_dev = [8106, 9910, 3397, 8870, 2103, 5689, 9799, 4037, 1584, 1160, 9063,\n",
    "       1332, 3043, 8307, 1042, 3466, 7772, 7327, 7098, 7216, 8624, 6400,\n",
    "       5811, 1862, 7327, 1626, 5958, 3868, 3795,  836, 3406, 5570, 9535,\n",
    "       9653, 7890, 5671, 2451, 9175, 8310, 2425, 5923, 2797, 1150, 6012,\n",
    "       8666, 8849, 6839, 5994, 6751, 9139, 9648, 8898, 9869, 2184, 1363,\n",
    "       8294, 4000, 5424, 4544,  330, 4325, 4597, 4735, 9966, 2342, 7220,\n",
    "       5774, 3437, 4276,  760, 7868, 2993, 6262, 8880, 6017, 5045, 9513,\n",
    "       4084, 7115, 5775,  358, 3549, 2612, 8973, 6747,  415, 8573, 9973,\n",
    "       2734,  586, 3937, 6889, 1191, 5255, 1460,  413, 7257, 5272, 7402,\n",
    "       7968]\n",
    "  X_train, Y_train, X_validation, Y_validation = load_standard_mnist()\n",
    "  X_dev = X_validation[selected_dev]\n",
    "  Y_dev = Y_validation[selected_dev]\n",
    "  return X_train, Y_train, X_dev, Y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_zklsWaSfOe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      " 2138112/11490434 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6700f484171d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mnist_train_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9f113fd5d090>\u001b[0m in \u001b[0;36mload_mnist_train_dev\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m        \u001b[0;36m2734\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m586\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3937\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6889\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1191\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1460\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m413\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7257\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5272\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7402\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m        7968]\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_standard_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m   \u001b[0mX_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_dev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0mY_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_validation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_dev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9f113fd5d090>\u001b[0m in \u001b[0;36mload_standard_mnist\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_standard_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_validation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mnist.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mX_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/datasets/mnist.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morigin_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'mnist.npz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0mfile_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m       '731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1')\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unexpected-keyword-arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mchunk_read\u001b[0;34m(response, chunk_size, reporthook)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreporthook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[1;32m    583\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkClosed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkReadable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot read from timed out object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_dev, Y_dev = load_mnist_train_dev()\n",
    "Y_train = get_one_hot(Y_train, 10)\n",
    "Y_dev = get_one_hot(Y_dev, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZonLT6kfqV0i"
   },
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "RV0o3BCIhN5H"
   },
   "outputs": [],
   "source": [
    "TRIAL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KWnk-esibhaL"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(BASE_DIR + '/tmp/mnist/original/{0}/model_ckpt_75.h5'.format(TRIAL))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDno9rcnkYR-"
   },
   "source": [
    "# Influence functions implemention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JIZnOneKiPEF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras import layers\n",
    "\n",
    "\n",
    "def flatten(tensor_list):\n",
    "  \"\"\"Flattens a list of tensor into a single rank-1 tensor.\"\"\"\n",
    "  return tf.concat([tf.reshape(x, [-1]) for x in tensor_list], 0)\n",
    "\n",
    "\n",
    "class InfSketchLayer(layers.Layer):\n",
    "  \"\"\"A Keras layer encapsulating the influence computation.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               base_params_fn,\n",
    "               base_model_num_params,\n",
    "               target=None,\n",
    "               sketch_size=100):\n",
    "    \"\"\"Constructs the InfSketchLayer.\n",
    "\n",
    "    Args:\n",
    "      base_params_fn: A callable returning a list of the base model parameters.\n",
    "      base_model_num_params: The total number of base model parameters.\n",
    "      target: An optional matrix of shape (sketch_size, base_model_num_params)\n",
    "        that will be the target matrix for the sketch computation. The sketch\n",
    "        computed will be Hessian^{-1} * target.\n",
    "      sketch_size: the size of the sketch. Larger values give\n",
    "        better accuracy but involve slower computation.\n",
    "    \"\"\"\n",
    "    super(InfSketchLayer, self).__init__()\n",
    "    self._sketch_size = sketch_size\n",
    "    self._base_params_fn = base_params_fn\n",
    "    if target is None:\n",
    "      self.target = self.add_weight(\n",
    "          name='target',\n",
    "          shape=(self._sketch_size, base_model_num_params),\n",
    "          dtype=tf.float32,\n",
    "          initializer=tf.keras.initializers.random_normal(stddev=1.0 /\n",
    "                                                          np.sqrt(sketch_size)),\n",
    "          trainable=False)\n",
    "    else:\n",
    "      self.target = target\n",
    "      self._sketch_size = target.shape[0]\n",
    "    self.sketch = self.add_weight(\n",
    "        name='sketch',\n",
    "        shape=self.target.shape,\n",
    "        initializer='zeros',\n",
    "        trainable=True)\n",
    "\n",
    "  def call(self, inputs, training=True):\n",
    "    \"\"\"inputs is expected to be the gradient of the loss.\"\"\"\n",
    "    if training:\n",
    "      grad1_x_sketch = tf.matmul(self.sketch, tf.reshape(inputs[0], [-1, 1]))\n",
    "      grad2_x_sketch = tf.matmul(self.sketch, tf.reshape(inputs[1], [-1, 1]))\n",
    "      base_params = self._base_params_fn()\n",
    "\n",
    "      def loss_i(i):\n",
    "        # si = self.sketch[i]\n",
    "        ti = self.target[i]\n",
    "        gs1 = grad1_x_sketch[i][0]\n",
    "        hs1 = tf.cast(flatten(tf.gradients(gs1, base_params)), tf.float32)\n",
    "        gs2 = grad2_x_sketch[i][0]\n",
    "        hs2 = tf.cast(flatten(tf.gradients(gs2, base_params)), tf.float32)\n",
    "        return tf.tensordot(hs1 - ti, hs2 - ti, 1)\n",
    "\n",
    "      _, loss = tf.while_loop(\n",
    "          lambda i, _: i < self._sketch_size,\n",
    "          lambda i, loss: (i + 1, loss + loss_i(i)),\n",
    "          [tf.constant(0, tf.int32),\n",
    "           tf.constant(0.0, tf.float32)])\n",
    "      output = tf.reshape(loss, [1, -1])\n",
    "    else:\n",
    "      grad_x_sketch = tf.matmul(self.sketch, inputs)\n",
    "      output = tf.matmul(tf.transpose(self.target), grad_x_sketch)\n",
    "    return output\n",
    "\n",
    "\n",
    "class LossGradientLayer(layers.Layer):\n",
    "  \"\"\"A Keras layer computing the gradient of the loss.\"\"\"\n",
    "\n",
    "  def __init__(self, base_model_fn):\n",
    "    super(LossGradientLayer, self).__init__()\n",
    "    self._base_model_fn = base_model_fn\n",
    "\n",
    "  def call(self, inputs):\n",
    "    base_loss, base_params = self._base_model_fn(inputs)\n",
    "    return tf.cast(flatten(tf.gradients(base_loss, base_params)), tf.float32)\n",
    "\n",
    "\n",
    "def _identity_loss(_, y_pred):\n",
    "  \"\"\"Defines the identity loss function.\"\"\"\n",
    "  return y_pred\n",
    "\n",
    "\n",
    "def _base_model_fns(base_model, loss_fn):\n",
    "  \"\"\"Helper function to construct base_model_fn and base_params_fn.\"\"\"\n",
    "  def base_model_fn(inputs):\n",
    "    features = inputs[0]\n",
    "    labels = inputs[1]\n",
    "    preds = base_model(features, training=False)\n",
    "    return loss_fn(labels, preds), base_model.trainable_variables\n",
    "\n",
    "  def base_params_fn():\n",
    "    return base_model.trainable_variables\n",
    "\n",
    "  return base_model_fn, base_params_fn\n",
    "\n",
    "\n",
    "def test_loss_grads(base_model, loss_fn, test_inputs):\n",
    "  \"\"\"Computes the loss gradient at the given test points.\"\"\"\n",
    "  num_points = test_inputs[0].shape[0]\n",
    "  features_input = tf.keras.Input(shape=test_inputs[0].shape[1:])\n",
    "  labels_input = tf.keras.Input(shape=test_inputs[1].shape[1:])\n",
    "  base_model_fn, _ = _base_model_fns(base_model, loss_fn)\n",
    "  test_grad = tf.reshape(\n",
    "      LossGradientLayer(base_model_fn)([features_input, labels_input]), [1, -1])\n",
    "  m = tf.keras.Model(inputs=[features_input, labels_input], outputs=test_grad)\n",
    "  grads = np.zeros((num_points, base_model.count_params()), dtype=np.float32)\n",
    "  for i in range(num_points):\n",
    "    grads[i] = m.predict([[test_inputs[0][i]], [test_inputs[1][i]]])[0]\n",
    "  return grads\n",
    "\n",
    "\n",
    "class InfSketcher(object):\n",
    "  \"\"\"A helper class encapsulating two models: sketcher_model and inf_model.\n",
    "\n",
    "  sketcher_model: computes the inverse Hessian sketch\n",
    "  inf_model: computes influences, accessed via the inf_model() function.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               base_model,\n",
    "               inputs,\n",
    "               loss_fn,\n",
    "               target=None,\n",
    "               sketch_size=100,\n",
    "               optimizer='sgd',\n",
    "               sketch_path=None):\n",
    "    base_model_fn, base_params_fn = _base_model_fns(base_model, loss_fn)\n",
    "    self._grad_layer = LossGradientLayer(base_model_fn)\n",
    "    f0, f1 = tf.split(inputs[0], 2)\n",
    "    l0, l1 = tf.split(inputs[1], 2)\n",
    "    grad1 = self._grad_layer([f0, l0])\n",
    "    grad2 = self._grad_layer([f1, l1])\n",
    "    self._is_layer = InfSketchLayer(base_params_fn, base_model.count_params(),\n",
    "                                    target, sketch_size)\n",
    "    train_loss = self._is_layer([grad1, grad2], training=True)\n",
    "    self.sketcher_model = tf.keras.Model(\n",
    "        inputs=inputs, outputs=train_loss)\n",
    "    self.sketcher_model.compile(optimizer=optimizer, loss=_identity_loss)\n",
    "    if sketch_path is not None:\n",
    "      self.sketcher_model.load_weights(sketch_path)\n",
    "\n",
    "  def get_inf_model(self, test_input, train_inputs):\n",
    "    \"\"\"Influence computing model using a single test point as target.\"\"\"\n",
    "    inf_grad = self._grad_layer(train_inputs)\n",
    "    test_grad = self._grad_layer(test_input)\n",
    "    invhess_x_test_grad = self._is_layer(\n",
    "        tf.reshape(test_grad, [-1, 1]), training=False)\n",
    "    influence = tf.reshape(tf.tensordot(inf_grad, invhess_x_test_grad, 1), [-1])\n",
    "    self.inf_model = tf.keras.Model(\n",
    "        inputs=train_inputs, outputs=influence)\n",
    "    return self.inf_model\n",
    "\n",
    "  def get_grads_inf_model(self, test_grads, train_inputs):\n",
    "    \"\"\"Influence computing model for target/test grads using the sketched inv hessian.\"\"\"\n",
    "\n",
    "    inf_grad = self._grad_layer(train_inputs)  # shape = [num_params]\n",
    "    invhess_x_test_grads = self._is_layer(\n",
    "        tf.transpose(test_grads),\n",
    "        training=False)  # shape = [num_params, num_test_inputs]\n",
    "    # influence of this training point over the test_grads provided.\n",
    "    influence = tf.reshape(\n",
    "        tf.matmul(tf.reshape(inf_grad, [1, -1]), invhess_x_test_grads),\n",
    "        [1, -1])  # shape = [num_test_inputs]\n",
    "    self.inf_model = tf.keras.Model(inputs=train_inputs, outputs=influence)\n",
    "    return self.inf_model\n",
    "\n",
    "  def target_inf_model(self, train_inputs):\n",
    "    inf_grad = self._grad_layer(train_inputs)\n",
    "    sketch_x_grad = tf.reshape(\n",
    "        tf.matmul(self._is_layer.sketch, tf.reshape(inf_grad, [-1, 1])),\n",
    "        [1, -1])\n",
    "    self.target_inf_model = tf.keras.Model(\n",
    "        inputs=train_inputs, outputs=sketch_x_grad)\n",
    "    return self.target_inf_model\n",
    "\n",
    "  def save(self, path):\n",
    "    self.sketcher_model.save_weights(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc55-GNM08--"
   },
   "source": [
    "# Influence on loss of test points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1662610972208,
     "user": {
      "displayName": "Hasan Amin",
      "userId": "17461130678708299500"
     },
     "user_tz": 240
    },
    "id": "DoXo-6O9e_3R",
    "outputId": "b039dc3e-4c71-4bde-9e85-e10597411629"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_points = [X_dev, Y_dev]\n",
    "test_grads = test_loss_grads(model, tf.keras.losses.CategoricalCrossentropy(), test_points)\n",
    "test_grads = tf.constant(test_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2d9R2knkW-R"
   },
   "outputs": [],
   "source": [
    "features_input = tf.keras.Input(shape=(28, 28, 1))\n",
    "labels_input = tf.keras.Input(shape=(10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3413,
     "status": "ok",
     "timestamp": 1661585767431,
     "user": {
      "displayName": "Hasan Amin",
      "userId": "17461130678708299500"
     },
     "user_tz": 240
    },
    "id": "f4DAK5XRMZL_",
    "outputId": "0967c876-7086-4e7f-e374-8fed1e1fa814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using sketch from drive/MyDrive/Colab Notebooks/SAME/sota/sota_mnist/tmp/mnist/original/1/sketcher_model.h5\n"
     ]
    }
   ],
   "source": [
    "sketch_path = BASE_DIR + '/tmp/mnist/original/{0}/sketcher_model.h5'.format(TRIAL)\n",
    "if os.path.exists(sketch_path):\n",
    "  print('using sketch from {0}'.format(sketch_path))\n",
    "  my_is = InfSketcher(model,\n",
    "                                [features_input, labels_input],\n",
    "                                tf.keras.losses.CategoricalCrossentropy(),\n",
    "                                target=test_grads,\n",
    "                                optimizer='adam',\n",
    "                                sketch_path=sketch_path)\n",
    "  sketcher_model = my_is.sketcher_model\n",
    "else:\n",
    "  print('sketch_path file does not exist, training a sketch')\n",
    "  my_is = InfSketcher(model,\n",
    "                                [features_input, labels_input],\n",
    "                                tf.keras.losses.CategoricalCrossentropy(),\n",
    "                                optimizer='adam',\n",
    "                                target=test_grads)\n",
    "  sketcher_model = my_is.sketcher_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6494435,
     "status": "ok",
     "timestamp": 1645178308366,
     "user": {
      "displayName": "Hasan Amin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3kp8k_QR5n481JXJjNGoiBLUorNBkkT2NPcEbOA=s64",
      "userId": "17461130678708299500"
     },
     "user_tz": 300
    },
    "id": "2K1oVs-Xqk0g",
    "outputId": "10280df7-617c-4b6d-c575-86c6c0add356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 60742.9642\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 46217.1348\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 39122.5755\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 34742.1113\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 31943.1641\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 30415.7933\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 29869.5146\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 28990.9912\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 28818.8405\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 28272.4548\n",
      "round 1\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 27899.0518\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 27299.8861\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 26916.0658\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 26499.9294\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 26428.8714\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 25959.0273\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 25710.6133\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 25333.2048\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 25234.3337\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 24789.6598\n",
      "round 2\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 24498.6865\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 24457.9183\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 24231.5879\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 24021.1943\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 23801.0729\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 23763.5908\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 24006.1328\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 23024.7708\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 23244.6533\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 22990.1191\n",
      "round 3\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 22808.6621\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 23007.4792\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 22399.3265\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 22663.1875\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 22432.9749\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 22082.0059\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 22339.7614\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 22017.8190\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 22117.2516\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 22026.3516\n",
      "round 4\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 21647.0576\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 21786.5508\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 22097.9443\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 21686.6641\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 21304.0579\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 21097.1032\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 21482.4668\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 21205.4225\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20948.9271\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 21511.1673\n",
      "round 5\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 21184.6592\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 21047.7793\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20917.8646\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20785.4215\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 21079.6631\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20673.9372\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 21357.6357\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20526.9261\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20720.0684\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20710.4733\n",
      "round 6\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20612.3652\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20315.8158\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20598.3717\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20522.6263\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20145.8874\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20265.1882\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20209.5264\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20167.3470\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20602.2493\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20051.1038\n",
      "round 7\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20153.7334\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20208.2633\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 19967.0488\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 20650.3467\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 19881.3831\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 19964.6279\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 19905.8926\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 19948.4984\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 19732.2295\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 19649.0990\n",
      "saved sketch to drive/MyDrive/Colab Notebooks/sota_mnist/tmp/mnist/original/1/sketcher_model.h5\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "  print('round {}'.format(i))\n",
    "  sketcher_model.fit(x=[X_train, Y_train], y=None, verbose=1, epochs=10, batch_size=10000)\n",
    "sketcher_model.save_weights(sketch_path)\n",
    "print('saved sketch to {0}'.format(sketch_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1645178308533,
     "user": {
      "displayName": "Hasan Amin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3kp8k_QR5n481JXJjNGoiBLUorNBkkT2NPcEbOA=s64",
      "userId": "17461130678708299500"
     },
     "user_tz": 300
    },
    "id": "a_Z5JtoBiBiY",
    "outputId": "205e26ea-d983-463f-8590-f7f6ad118a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_op_layer_split (TensorFlowO  [(None, 28, 28, 1),  0          ['input_3[0][0]']                \n",
      " pLayer)                         (None, 28, 28, 1)]                                               \n",
      "                                                                                                  \n",
      " tf_op_layer_split_1 (TensorFlo  [(None, 10),        0           ['input_4[0][0]']                \n",
      " wOpLayer)                       (None, 10)]                                                      \n",
      "                                                                                                  \n",
      " loss_gradient_layer_1 (LossGra  (244522,)           0           ['tf_op_layer_split[0][0]',      \n",
      " dientLayer)                                                      'tf_op_layer_split_1[0][0]',    \n",
      "                                                                  'tf_op_layer_split[0][1]',      \n",
      "                                                                  'tf_op_layer_split_1[0][1]']    \n",
      "                                                                                                  \n",
      " inf_sketch_layer (InfSketchLay  (1, 1)              24452200    ['loss_gradient_layer_1[0][0]',  \n",
      " er)                                                              'loss_gradient_layer_1[1][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,452,200\n",
      "Trainable params: 24,452,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_is.sketcher_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 149092,
     "status": "ok",
     "timestamp": 1645178884400,
     "user": {
      "displayName": "Hasan Amin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3kp8k_QR5n481JXJjNGoiBLUorNBkkT2NPcEbOA=s64",
      "userId": "17461130678708299500"
     },
     "user_tz": 300
    },
    "id": "xvYPW35hFnvF",
    "outputId": "17b11014-5d89-4bf3-d690-ee606de0ab1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "target_inf_model = my_is.target_inf_model([features_input, labels_input])\n",
    "influences = np.zeros(shape=(60000,100), dtype=np.float32)\n",
    "for i in range(60000):\n",
    "  if (i % 10000) == 0:\n",
    "    print(i)\n",
    "  influences[i] = my_is.target_inf_model.predict([[X_train[i]], [Y_train[i]]])[0]\n",
    "# np.savez_compressed('/tmp/ckpts/{0}/dev_influences_inf_fun.npz'.format(TRIAL), influences)\n",
    "np.savez_compressed(BASE_DIR + '/tmp/mnist/original/{0}/dev_influences_inf_fun.npz'.format(TRIAL), influences)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "",
   "provenance": [
    {
     "file_id": "1xJR8xmgGjZ5Te44ryidLWv8wBL05e4_L",
     "timestamp": 1582082742603
    },
    {
     "file_id": "16h0Gf9ymL7w7_8MT82zvjpRvQTma8uOn",
     "timestamp": 1582066357338
    }
   ],
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
