{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMRhQ9WtoEeR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist, cifar10\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input, Activation, BatchNormalization, UpSampling2D, Reshape\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkNVNsx1yDI4"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "WIDTH = 32\n",
    "NUM_CHANNELS = 3\n",
    "NUM_TRAIN = 50000\n",
    "NUM_TEST = 10000\n",
    "NUM_DEV = 100\n",
    "\n",
    "DATASET = \"cifar10\"\n",
    "BASE_DIR = f\"\"\n",
    "\n",
    "TRIAL = 1\n",
    "MODEL_DIR = f\"{BASE_DIR}/tmp/{DATASET}/original/{TRIAL}/model_ckpt_11.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsOawdUMoL8s"
   },
   "outputs": [],
   "source": [
    "def _normalize(X):\n",
    "  assert X.dtype == np.uint8\n",
    "  X = X.astype(np.float64)\n",
    "  X /= 255\n",
    "  return X\n",
    "\n",
    "def get_one_hot(targets, nb_classes):\n",
    "  res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "  return res.reshape(list(targets.shape)+[nb_classes])\n",
    "\n",
    "def load_standard_cifar10():\n",
    "  (X_train, Y_train), (X_validation, Y_validation) = tf.keras.datasets.cifar10.load_data()\n",
    "  X_train = X_train.reshape(X_train.shape[0], WIDTH, WIDTH, NUM_CHANNELS)\n",
    "  X_validation = X_validation.reshape(X_validation.shape[0], WIDTH, WIDTH, NUM_CHANNELS)\n",
    "\n",
    "  X_train = _normalize(X_train)\n",
    "  X_validation = _normalize(X_validation)\n",
    "\n",
    "  Y_train = Y_train.astype(np.int32)\n",
    "  Y_validation = Y_validation.astype(np.int32)\n",
    "\n",
    "  return X_train, Y_train, X_validation, Y_validation\n",
    "\n",
    "def load_cifar10_train_dev(num_dev=100):\n",
    "  # randomly select and fixed for future (tracin-like strategy but their indices available only for mnist)\n",
    "  # selected_dev = np.random.randint(0, X_validation.shape[0], num_dev)\n",
    "  selected_dev = [5214, 2304, 5947, 9428, 2717, 8296, 7736, 8291, 5235, 54,\n",
    "                  7499, 9590, 3675, 1932, 6646, 8719, 6484, 6306, 3066, 2442,\n",
    "                  6106, 1949, 4320,  541, 1318, 5967, 2773, 3847, 1152, 9937,\n",
    "                  7469, 5982, 7644, 5820, 8152, 9518,  601, 3953, 4931, 1924,\n",
    "                  5342, 5467, 6718, 6779, 2860, 2440, 5480, 1178,  222, 7909,\n",
    "                  6394, 3511, 8729, 6261, 7192, 9453, 5257, 9077, 6419, 3280,\n",
    "                  3725, 3601, 8174, 5703, 4954, 9536, 4783, 2234, 7365, 2405,\n",
    "                  3073, 2780, 7461, 3525, 7573, 6764, 9962, 7527,  992,  315,\n",
    "                  6260, 9061,  592, 8003, 7594, 1930, 7215, 5124, 7531, 9471,\n",
    "                  2824, 3533, 6062, 3946, 5246, 4440,  414, 3572, 4899, 884]\n",
    "  X_train, Y_train, X_validation, Y_validation = load_standard_cifar10()\n",
    "  X_dev = X_validation[selected_dev]\n",
    "  Y_dev = Y_validation[selected_dev]\n",
    "  return X_train, Y_train, X_dev, Y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLWdVnLRhZ7a"
   },
   "outputs": [],
   "source": [
    "def set_max_to_one(a):\n",
    "    idx = a.argmax(axis=1)\n",
    "    return (idx[:,None] == np.arange(a.shape[1])).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaBSs5ZNoNMb",
    "outputId": "4c202c95-df6f-4328-dabe-892dd4b7e13c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_dev, Y_dev = load_cifar10_train_dev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSp9Wxqt2qRg"
   },
   "outputs": [],
   "source": [
    "Y_train = np.squeeze(Y_train)\n",
    "Y_dev = np.squeeze(Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRJrpg4FadY1"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(MODEL_DIR)\n",
    "Y_pred_tr = model.predict(X_train)\n",
    "Y_pred_dev = model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y21vnRfadtnB"
   },
   "outputs": [],
   "source": [
    "_, _, X_test, Y_test = load_standard_cifar10()\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_pred_te = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7X7byiETtbgz"
   },
   "outputs": [],
   "source": [
    "# using prediction as embedding\n",
    "def get_similarity_pred(m, x, X_train):\n",
    "  # X_train: (Entire) training set\n",
    "  # x: single data point\n",
    "  X_emb_tr = m.predict(X_train)\n",
    "  x_emb = m.predict(x[np.newaxis,:])\n",
    "\n",
    "  # can be another distance as well\n",
    "  similarity = euclidean_dist(X_emb_tr, x_emb, axis=1)\n",
    "  return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCfTWOOstcDt"
   },
   "outputs": [],
   "source": [
    "# using penultimate layer as embedding\n",
    "def get_similarity_penult(m, x, X_train):\n",
    "  # X_train: (Entire) training set\n",
    "  # x: single data point\n",
    "  m_p = tf.keras.models.Model(m.inputs, m.layers[-3].output)  # penultimate layer output (last 2 layers here for logit and softmax)\n",
    "\n",
    "  X_emb_tr = m_p.predict(X_train)\n",
    "  x_emb = m_p.predict(x[np.newaxis,:])\n",
    "\n",
    "  # can be another distance as well\n",
    "  similarity = euclidean_dist(X_emb_tr, x_emb, axis=1)\n",
    "  return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDDJaceRwZjt"
   },
   "outputs": [],
   "source": [
    "pred_sim = [get_similarity_pred(model, x, X_train) for x in X_dev]\n",
    "pred_infl = -1*np.array(pred_sim)\n",
    "np.save(BASE_DIR + '/pred_infl.npy', pred_infl, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWX-wsRauF9a"
   },
   "outputs": [],
   "source": [
    "penult_sim = [get_similarity_penult(model, x, X_train) for x in X_dev]\n",
    "penult_infl = -1*np.array(penult_sim)\n",
    "np.save(BASE_DIR + '/penult_infl.npy', penult_infl, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
